{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate GLMsingle on control_beta subjects (spring 2022)\n",
    "---------------------\n",
    "\n",
    "##### Visualize output interactively.\n",
    "\n",
    "For sanity checking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import function libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/glmdenoise/lib/python3.8/site-packages/nilearn/datasets/__init__.py:93: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running as user gt\n",
      "\n",
      "\n",
      " ---------- Running version from /Users/gt/om5/GLMsingle ---------- \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "from nilearn import plotting\n",
    "\n",
    "import h5py\n",
    "import os\n",
    "from os.path import join, exists, split\n",
    "import sys\n",
    "import time\n",
    "import urllib.request\n",
    "import copy\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import sys\n",
    "import datetime\n",
    "import getpass\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "user = getpass.getuser()\n",
    "print(f'Running as user {user}')\n",
    "if user != 'gt':\n",
    "    root = '/om5/group/evlab/u/gretatu/GLMsingle/'\n",
    "else:\n",
    "    root = '/Users/gt/om5/GLMsingle/'\n",
    "    \n",
    "os.chdir(root)\n",
    "\n",
    "import glmsingle\n",
    "from glmsingle.glmsingle import GLM_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RESOURCES ###\n",
    "d_UID_to_session_list = {848: ['FED_20220420b_3T1', 'FED_20220427a_3T1'],\n",
    "\t\t\t\t\t\t 853: ['FED_20211008a_3T1', 'FED_20211013b_3T1'],\n",
    "\t\t\t\t\t\t 865: ['FED_20220414b_3T1', 'FED_20220415a_3T1'],\n",
    "\t\t\t\t\t\t 875: ['FED_20220408a_3T1', 'FED_20220411a_3T1'],\n",
    "\t\t\t\t\t\t 876: ['FED_20220413a_3T1', 'FED_20220420a_3T1']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set paths and download the example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "865_FED_20220414b_3T1\n"
     ]
    }
   ],
   "source": [
    "# subject args\n",
    "UID = 865\n",
    "if len(str(UID)) < 3:\n",
    "    UID_str = f'0{UID}'\n",
    "else:\n",
    "    UID_str = str(UID)\n",
    "\n",
    "# GLM args\n",
    "pcstop = -1\n",
    "fracs = 0.975\n",
    "\n",
    "# data args\n",
    "preproc = 'swr'\n",
    "\n",
    "# get path to the directory to which GLMsingle was installed\n",
    "homedir = split(os.getcwd())[0]\n",
    "htmldir = join(root, 'output_glmsingle', 'html_plots')\n",
    "outputdir = join(root, 'output_glmsingle', f'output_glmsingle_preproc-{preproc}_pcstop{pcstop}_fracs-{fracs}_UID-{UID}')\n",
    "datadir = '/mindhive/evlab/u/Shared/SUBJECTS'\n",
    "headersession = f'{UID_str}_{d_UID_to_session_list[UID][0]}'\n",
    "print(headersession)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TYPEA_ONOFF.hdf5',\n",
       " 'onoffR2.png',\n",
       " 'meanvol.png',\n",
       " 'onoffR2hist.png',\n",
       " 'TYPEB_FITHRF.hdf5',\n",
       " 'HRFindex.png',\n",
       " 'TYPEC_FITHRF_GLMDENOISE.hdf5',\n",
       " 'noisepool.png',\n",
       " 'TYPED_FITHRF_GLMDENOISE_RR.hdf5',\n",
       " 'typeD_R2.png',\n",
       " 'FRACvalue.png']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(outputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRACvalue\n",
      "HRFindex\n",
      "HRFindexrun\n",
      "R2\n",
      "R2run\n",
      "betasmd\n",
      "meanvol\n",
      "noisepool\n",
      "pcnum\n",
      "pcregressors\n",
      "rrbadness\n",
      "scaleoffset\n"
     ]
    }
   ],
   "source": [
    "typea = h5py.File(join(outputdir, 'TYPEA_ONOFF.hdf5'), 'r')\n",
    "typeb = h5py.File(join(outputdir, 'TYPEB_FITHRF.hdf5'), 'r')\n",
    "typec = h5py.File(join(outputdir, 'TYPEC_FITHRF_GLMDENOISE.hdf5'), 'r')\n",
    "typed = h5py.File(join(outputdir, 'TYPED_FITHRF_GLMDENOISE_RR.hdf5'), 'r')\n",
    "\n",
    "for name in typed:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of important outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the outputs of GLMsingle are formally documented in its\n",
    "# header. here, we highlight a few of the more important outputs:\n",
    "\n",
    "# R2 -> is model accuracy expressed in terms of R^2 (percentage).\n",
    "\n",
    "# betasmd -> is the full set of single-trial beta weights (X x Y x Z x\n",
    "# TRIALS). beta weights are arranged in chronological order.\n",
    "\n",
    "# HRFindex -> is the 1-index of the best fit HRF. HRFs can be recovered\n",
    "# with getcanonicalHRFlibrary(stimdur,tr)\n",
    "\n",
    "# FRACvalue -> is the fractional ridge regression regularization level\n",
    "# chosen for each voxel. values closer to 1 mean less regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a slice of brain showing GLMsingle outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz = np.array(typed['R2']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# we are going to plot several outputs from the FIT_HRF_GLMdenoise_RR GLM,\n",
    "# which contains the full set of GLMsingle optimizations.\n",
    "\n",
    "# we will plot betas, R2, optimal HRF indices, and the voxel frac values\n",
    "plot_fields = ['betasmd','R2','HRFindex',] # 'FRACvalue'\n",
    "colormaps = ['RdBu_r','hot','jet','copper']\n",
    "clims = [[-1,1],[0,85],[0,20],[0,1]]\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "for i in range(len(plot_fields)):\n",
    "    print(i)\n",
    "    \n",
    "    plt.subplot(2,2,i+1)\n",
    "    \n",
    "    if plot_fields[i] == 'betasmd':\n",
    "        # when plotting betas, for simplicity just average across all image presentations\n",
    "        # this will yield a summary of whether voxels tend to increase or decrease their \n",
    "        # activity in response to the experimental stimuli (similar to outputs from \n",
    "        # an ONOFF GLM)\n",
    "        plot_data = np.nanmean((np.array(typed[plot_fields[i]])),3)\n",
    "        titlestr = 'average GLM betas'\n",
    "    \n",
    "    else:\n",
    "        # plot all other voxel-wise metrics as outputted from GLMsingle\n",
    "        plot_data = np.squeeze(np.array(typed[plot_fields[i]]).reshape(xyz))\n",
    "        titlestr = plot_fields[i]\n",
    "    \n",
    "    plt.imshow(plot_data[:,:,65],cmap=colormaps[i],clim=clims[i]) # added indexing here, otherwise it errrors\n",
    "    plt.colorbar()\n",
    "    plt.title(titlestr)\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View more outputs from all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_str = 'typed'\n",
    "\n",
    "if type_str == 'typec':\n",
    "    type_of_interest = typec\n",
    "elif type_str == 'typed':\n",
    "    type_of_interest = typed\n",
    "else:\n",
    "    raise ValueError()\n",
    "\n",
    "plot_fields = ['meanvol','betasmd','R2','HRFindex','noisepool',]\n",
    "d_cmap = {'betasmd':'RdBu_r', \n",
    "         'R2':'hot',\n",
    "         'HRFindex':'jet',\n",
    "         'noisepool':'hot',\n",
    "         'pcvoxels':'hot',\n",
    "         'FRACvalue':'copper',\n",
    "         'glmbadness':'hot',\n",
    "         'meanvol':'Greys'}\n",
    "\n",
    "d_clim = {'betasmd': [-1,1], \n",
    "         'R2': [30,90],\n",
    "         'HRFindex':[0,20],\n",
    "         'noisepool':[0,1],\n",
    "         'pcvoxels':[0,1],\n",
    "         'FRACvalue':[0,1],\n",
    "         'glmbadness':[0,10],\n",
    "         'meanvol':[0,800]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,14))\n",
    "\n",
    "for i in range(len(plot_fields)):\n",
    "    \n",
    "    plt.subplot(2,4,i+1)\n",
    "    \n",
    "    if plot_fields[i] == 'betasmd' or plot_fields[i] == 'glmbadness':\n",
    "        plot_data = np.nanmean((np.array(type_of_interest[plot_fields[i]])),3) # avg over trials\n",
    "        titlestr = plot_fields[i]\n",
    "    \n",
    "    else:\n",
    "        # plot all other voxel-wise metrics as outputted from GLMsingle and reshape to the brain\n",
    "        plot_data = np.squeeze(np.array(type_of_interest[plot_fields[i]]).reshape(xyz))\n",
    "        titlestr = plot_fields[i]\n",
    "    \n",
    "    plt.imshow(plot_data[:,:,50],cmap=d_cmap[plot_fields[i]],clim=d_clim[plot_fields[i]])\n",
    "    plt.colorbar()\n",
    "    plt.title(f'{titlestr} - axial slice, (z=50)') # right is front here\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmean(np.squeeze(results_glmsingle['typec']['betasmd']),3).shape # glm betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(results_glmsingle['typec']['meanvol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_3D_coords(shape):\n",
    "    \"\"\"Get 3D coordinates for the flattened voxel array (column to coordinate)\n",
    "    Based on these coords, it is possible to create an empty brain matrix of shape [shape] and fill in values.\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    for idx in np.ndindex(shape):\n",
    "        indices.append(np.array(idx))\n",
    "    # print('OBS: adding +1 for MATLAB')\n",
    "    coords = (np.array(indices)).astype(int)\n",
    "    return coords\n",
    "\n",
    "\n",
    "def fill_empty_brain_matrix(shape, vals_of_interest, coords_3d, save_plot=False, save_nii=False,\n",
    "                            save_str='', headerpath='/mindhive/evlab/u/Shared/SUBJECTS'):\n",
    "    \"\"\"\n",
    "    Fill an 'empty' brain matrix with values to plot.\n",
    "\n",
    "    :param shape: Tuple, the 3D shape of the brain space, e.g. (91, 109, 91)\n",
    "    :param header_file: str, path to a .nii file in the same coordinate system\n",
    "    :param vals_of_interest: the flattened \"brain\" array to plot, i.e. if shape is (91, 109, 91) this\n",
    "    has size 902,629. Or in the original shape (3D). If so, only header info is added.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if len(vals_of_interest.shape) == 1: # Flat array given\n",
    "        ## Plot values of interest in a 3d brain matrix\n",
    "        empty_brain = np.zeros([shape[0], shape[1], shape[2]])\n",
    "        for idx, i in enumerate(vals_of_interest):\n",
    "            x = coords_3d[idx][0]\n",
    "            y = coords_3d[idx][1]\n",
    "            z = coords_3d[idx][2]\n",
    "            empty_brain[x, y, z] = i\n",
    "    elif len(vals_of_interest.shape) == 3: # 3D brain already! just add header info.\n",
    "        empty_brain = vals_of_interest\n",
    "    else:\n",
    "        raise ValueError('invalid shape!')\n",
    "    \n",
    "    # Load a header file\n",
    "    n1_img = nib.load(headerpath)\n",
    "    new_header = header = n1_img.header.copy()\n",
    "    \n",
    "    new_img = nib.nifti1.Nifti1Image(empty_brain, n1_img.affine, header=new_header)\n",
    "    \n",
    "    if save_plot:\n",
    "        plotting.plot_stat_map(new_img, output_file=join(PLOTDIR, f'{UID}_{SESSION}_{FL}_{save_str}_statmap.png'))\n",
    "        plotting.plot_glass_brain(new_img, output_file=join(PLOTDIR, f'{UID}_{SESSION}_{FL}_{save_str}_glassbrain.png'),\n",
    "                                  colorbar=True, alpha=0.1)\n",
    "        plotting.plot_roi(new_img, output_file=join(PLOTDIR, f'{UID}_{SESSION}_{FL}_{save_str}_roi.png'))\n",
    "    \n",
    "    if save_nii:\n",
    "        nib.save(new_img, join(NEWNIIDIR, f'{UID_SESSION}_{FL}_{save_str}.nii'))\n",
    "        \n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3D coordinate info ##\n",
    "coords_3d = get_3D_coords(shape=xyz)\n",
    "vals_of_interest = np.squeeze(results_glmsingle['typec'][plot_fields[3]].flatten())\n",
    "img = fill_empty_brain_matrix(shape=xyz, vals_of_interest=vals_of_interest,\n",
    "                             coords_3d=coords_3d, )\n",
    "\n",
    "\n",
    "plotting.view_img(img, symmetric_cmap=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop across 3D images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save as html files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find header image that fits the UID and preproc of interest\n",
    "# Load a header file\n",
    "possible_header_imgs = os.listdir(join(datadir, headersession, 'nii')) # find any nii file that matches the input neural data\n",
    "possible_header_imgs = [x for x in possible_header_imgs if x.startswith(preproc)]\n",
    "\n",
    "PATH_header_img = join(datadir, headersession, 'nii', possible_header_imgs[0])\n",
    "print(f'Using {PATH_header_img} as the header file\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(plot_fields)):\n",
    "    coords_3d = get_3D_coords(shape=xyz)\n",
    "\n",
    "    if plot_fields[i] == 'betasmd':\n",
    "        plot_data = np.nanmean((np.array(type_of_interest[plot_fields[i]])),3) # avg over trials\n",
    "    \n",
    "    else:\n",
    "        # plot all other voxel-wise metrics as outputted from GLMsingle and reshape to the brain\n",
    "        plot_data = np.squeeze(np.array(type_of_interest[plot_fields[i]]))\n",
    "\n",
    "    titlestr = plot_fields[i]\n",
    "        \n",
    "    # Feed to fill brain function\n",
    "    img = fill_empty_brain_matrix(shape=xyz, vals_of_interest=plot_data,\n",
    "                             coords_3d=coords_3d, headerpath=PATH_header_img)\n",
    "\n",
    "\n",
    "    view = plotting.view_img(img, symmetric_cmap=True, \n",
    "                             vmin=d_clim[plot_fields[i]][0], vmax=d_clim[plot_fields[i]][1],\n",
    "                            title=titlestr, cmap=d_cmap[plot_fields[i]])\n",
    "    \n",
    "#     view.open_in_browser()\n",
    "    view.save_as_html(join(htmldir, f'{titlestr}_preproc-{preproc}_pcstop{pcstop}_fracs-{fracs}_UID-{UID}.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "if plot_fields[i] == 'betasmd':\n",
    "    plot_data = np.nanmean(np.squeeze(results_glmsingle['typec'][plot_fields[i]]),3) # avg over trials\n",
    "    titlestr = 'average GLM betas (1000 stimuli)'\n",
    "\n",
    "else:\n",
    "    # plot all other voxel-wise metrics as outputted from GLMsingle and reshape to the brain\n",
    "    plot_data = np.squeeze(results_glmsingle['typec'][plot_fields[i]])\n",
    "    titlestr = plot_fields[i]\n",
    "\n",
    "# Feed to fill brain function\n",
    "img = fill_empty_brain_matrix(shape=xyz, vals_of_interest=plot_data,\n",
    "                         coords_3d=coords_3d, )\n",
    "\n",
    "\n",
    "plotting.view_img(img, symmetric_cmap=True, \n",
    "                         vmin=d_clim[plot_fields[i]][0], vmax=d_clim[plot_fields[i]][1],\n",
    "                        title=titlestr, cmap=d_cmap[plot_fields[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "if plot_fields[i] == 'betasmd':\n",
    "    plot_data = np.nanmean(np.squeeze(results_glmsingle['typec'][plot_fields[i]]),3) # avg over trials\n",
    "    titlestr = 'average GLM betas (1000 stimuli)'\n",
    "\n",
    "else:\n",
    "    # plot all other voxel-wise metrics as outputted from GLMsingle and reshape to the brain\n",
    "    plot_data = np.squeeze(results_glmsingle['typec'][plot_fields[i]])\n",
    "    titlestr = plot_fields[i]\n",
    "\n",
    "# Feed to fill brain function\n",
    "img = fill_empty_brain_matrix(shape=xyz, vals_of_interest=plot_data,\n",
    "                         coords_3d=coords_3d, )\n",
    "\n",
    "\n",
    "plotting.view_img(img, symmetric_cmap=True, \n",
    "                         vmin=d_clim[plot_fields[i]][0], vmax=d_clim[plot_fields[i]][1],\n",
    "                        title=titlestr, cmap=d_cmap[plot_fields[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=2\n",
    "if plot_fields[i] == 'betasmd':\n",
    "    plot_data = np.nanmean(np.squeeze(results_glmsingle['typec'][plot_fields[i]]),3) # avg over trials\n",
    "    titlestr = 'average GLM betas (1000 stimuli)'\n",
    "\n",
    "else:\n",
    "    # plot all other voxel-wise metrics as outputted from GLMsingle and reshape to the brain\n",
    "    plot_data = np.squeeze(results_glmsingle['typec'][plot_fields[i]])\n",
    "    titlestr = plot_fields[i]\n",
    "\n",
    "# Feed to fill brain function\n",
    "img = fill_empty_brain_matrix(shape=xyz, vals_of_interest=plot_data,\n",
    "                         coords_3d=coords_3d, )\n",
    "\n",
    "\n",
    "plotting.view_img(img, symmetric_cmap=False, \n",
    "                         vmin=d_clim[plot_fields[i]][0], vmax=d_clim[plot_fields[i]][1],\n",
    "                        title=titlestr, cmap=d_cmap[plot_fields[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_clim[plot_fields[i]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.view_img(img, symmetric_cmap=False, \n",
    "                        title=titlestr, annotate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=3\n",
    "if plot_fields[i] == 'betasmd':\n",
    "    plot_data = np.nanmean(np.squeeze(results_glmsingle['typec'][plot_fields[i]]),3) # avg over trials\n",
    "    titlestr = 'average GLM betas (1000 stimuli)'\n",
    "\n",
    "else:\n",
    "    # plot all other voxel-wise metrics as outputted from GLMsingle and reshape to the brain\n",
    "    plot_data = np.squeeze(results_glmsingle['typec'][plot_fields[i]])\n",
    "    titlestr = plot_fields[i]\n",
    "\n",
    "# Feed to fill brain function\n",
    "img = fill_empty_brain_matrix(shape=xyz, vals_of_interest=plot_data,\n",
    "                         coords_3d=coords_3d, )\n",
    "\n",
    "\n",
    "plotting.view_img(img, symmetric_cmap=True, \n",
    "                         vmin=d_clim[plot_fields[i]][0], vmax=d_clim[plot_fields[i]][1],\n",
    "                        title=titlestr, cmap=d_cmap[plot_fields[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=4\n",
    "if plot_fields[i] == 'betasmd':\n",
    "    plot_data = np.nanmean(np.squeeze(results_glmsingle['typec'][plot_fields[i]]),3) # avg over trials\n",
    "    titlestr = 'average GLM betas (1000 stimuli)'\n",
    "\n",
    "else:\n",
    "    # plot all other voxel-wise metrics as outputted from GLMsingle and reshape to the brain\n",
    "    plot_data = np.squeeze(results_glmsingle['typec'][plot_fields[i]])\n",
    "    titlestr = plot_fields[i]\n",
    "\n",
    "# Feed to fill brain function\n",
    "img = fill_empty_brain_matrix(shape=xyz, vals_of_interest=plot_data,\n",
    "                         coords_3d=coords_3d, )\n",
    "\n",
    "\n",
    "plotting.view_img(img, symmetric_cmap=True, \n",
    "                         vmin=d_clim[plot_fields[i]][0], vmax=d_clim[plot_fields[i]][1],\n",
    "                        title=titlestr, cmap=d_cmap[plot_fields[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare how the R2 value changes by fitting HRF for each voxel (type C) model vs simply one HRF for each voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_glmsingle.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_glmsingle['typec'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(results_glmsingle['typec']['R2']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmean(np.nanmean(results_glmsingle['typec']['R2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmean(np.nanmean(results_glmsingle['typeb']['R2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(results_glmsingle['typea']).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmean(np.nanmean(results_glmsingle['typea']['onoffR2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a baseline GLM to compare with GLMsingle outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for comparison purposes we are going to run a standard GLM\n",
    "# without HRF fitting, GLMdenoise, or ridge regression regularization. we\n",
    "# will compute the split-half reliability at each voxel using this baseline\n",
    "# GLM, and then assess whether reliability improves using the output betas\n",
    "# from GLMsingle. \n",
    "\n",
    "# output directory for baseline GLM\n",
    "outputdir_baseline = join(outputdir,'GLMbaseline')\n",
    "\n",
    "# we will run this baseline GLM by changing the default settings in GLMsingle \n",
    "# contained within the \"opt\" structure.\n",
    "opt = dict() \n",
    "\n",
    "# turn off optimizations \n",
    "opt['wantlibrary'] = 0 # switch off HRF fitting\n",
    "opt['wantglmdenoise'] = 0 # switch off GLMdenoise\n",
    "opt['wantfracridge'] = 0 # switch off ridge regression\n",
    "\n",
    "\n",
    "# for the purpose of this example we will keep the relevant outputs in memory\n",
    "# and also save them to the disk...\n",
    "# the first two indices are the ON-OFF GLM and the baseline single-trial GLM. \n",
    "# no need to save the third (+ GLMdenoise) and fourth (+ fracridge) outputs\n",
    "# since they will not even be computed\n",
    "opt['wantmemoryoutputs'] = [1,1,0,0] \n",
    "opt['wantfileoutputs'] = [1,1,0,0]\n",
    "\n",
    "# running python GLMsingle involves creating a GLM_single object\n",
    "# and then running the procedure using the .fit() routine\n",
    "glmbaseline_obj = GLM_single(opt)\n",
    "\n",
    "# visualize the hyperparameters, including the modified baseline opts\n",
    "pprint(glmbaseline_obj.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# if these outputs don't already exist, we will perform the call to\n",
    "# GLMsingle; otherwise, we will just load from disk.\n",
    "if not exists(outputdir_baseline):\n",
    "    \n",
    "    print(f'running GLMsingle...')\n",
    "\n",
    "    # run GLMsingle, fitting the baseline GLM\n",
    "    results_assumehrf = glmbaseline_obj.fit(\n",
    "       design,\n",
    "       data,\n",
    "       stimdur,\n",
    "       tr,\n",
    "       outputdir=outputdir_baseline)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    print(f'loading existing GLMsingle outputs from directory:\\n\\t{outputdir_glmsingle}')\n",
    "    \n",
    "    results_assumehrf = dict()\n",
    "    results_assumehrf['typea'] = np.load(join(outputdir_baseline,'TYPEA_ONOFF.npy'),allow_pickle=True).item()\n",
    "    results_assumehrf['typeb'] = np.load(join(outputdir_baseline,'TYPEB_FITHRF.npy'),allow_pickle=True).item()\n",
    "    \n",
    "    # note that even though we are loading TYPEB_FITHRF betas, HRF fitting\n",
    "    # has been turned off and this struct field will thus contain the\n",
    "    # outputs of a GLM fit using the canonical HRF.\n",
    "    \n",
    "elapsed_time = time.time() - start_time\n",
    "print(\n",
    "    '\\telapsed time: ',\n",
    "    f'{time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary containing the GLM betas from the four different models we will compare.\n",
    "# note that the \"assume hrf\" betas come from the \"typeb\" field of our baseline GLM\n",
    "# (with HRF fitting turned off), and that the \"fit hrf\" betas also come from \n",
    "# the \"typeb\" field of the GLM that ran with all default GLMsingle routines\n",
    "# enabled\n",
    "\n",
    "models = dict()\n",
    "models['assumehrf'] = results_assumehrf['typeb']['betasmd'].reshape(xyz + (750,))\n",
    "models['fithrf'] = results_glmsingle['typeb']['betasmd']\n",
    "models['fithrf_glmdenoise'] = results_glmsingle['typec']['betasmd']\n",
    "models['fithrf_glmdenoise_rr'] = results_glmsingle['typed']['betasmd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize cortical ROI defining visually-responsive areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mask defining liberal visual cortex ROI. \"nsdgeneral\" is a general ROI \n",
    "# that was manually drawn on fsaverage covering voxels responsive to the NSD experiment \n",
    "# in the posterior aspect of cortex. for the sake of simplicity we will focus \n",
    "# on voxels within this ROI in computing split-half reliability\n",
    "\n",
    "nsdgeneral_roi = roi.astype(float)\n",
    "\n",
    "# convert voxels outside ROI to nan for overlay plotting\n",
    "nsdgeneral_roi[nsdgeneral_roi==0] = np.nan \n",
    "\n",
    "# get mean fMRI volume from run 1\n",
    "meanvol = np.squeeze(np.mean(data[0].reshape(xyzt),axis=3))\n",
    "\n",
    "# plot ROI on top of overlay\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.imshow(meanvol,cmap='gray')\n",
    "plt.imshow(nsdgeneral_roi,cmap='Blues',clim=(0,2))\n",
    "\n",
    "plt.title('voxels in nsdgeneral ROI')\n",
    "plt.box(False)\n",
    "plt.axis(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute median split-half reliability within the ROI for each beta version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, let's compute split-half reliability. we are going to loop\n",
    "# through our 4 models and calculate split-half reliability for each of them\n",
    "\n",
    "vox_reliabilities = [] # output variable for reliability values\n",
    "\n",
    "modelnames = list(models.keys())\n",
    "\n",
    "# for each beta version...\n",
    "for m in range(len(modelnames)):\n",
    "    \n",
    "    print(f'computing reliability for beta version: {modelnames[m]}')\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # get the repeated-condition GLM betas using our repindices variable\n",
    "    betas = models[modelnames[m]][:,:,:,repindices] # automatically reshapes to (X x Y x Z x 2 x nConditions)\n",
    "    x,y,z = betas.shape[:3] \n",
    "    \n",
    "    rels = np.full((x,y,z),np.nan)\n",
    "    \n",
    "    # loop through voxels in the 3D volume...\n",
    "    for xx in tqdm(range(x)):\n",
    "        for yy in range(y):\n",
    "            for zz in range(z):\n",
    "                \n",
    "                # reliability at a given voxel is pearson correlation between response profiles from first and \n",
    "                # second image presentations (dim = 136 conditions)\n",
    "                rels[xx,yy,zz] = np.corrcoef(betas[xx,yy,zz,0],\n",
    "                                             betas[xx,yy,zz,1])[1,0]\n",
    "          \n",
    "    vox_reliabilities.append(rels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess change in reliability yielded by GLMsingle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each GLM we will calculate median reliability for voxels within the\n",
    "# nsdgeneral visual ROI and compare using a bar graph\n",
    "\n",
    "comparison = []\n",
    "for vr in vox_reliabilities:\n",
    "    comparison.append(np.nanmedian(vr[nsdgeneral_roi==1]))\n",
    "\n",
    "plt.figure(figsize=(18,6))\n",
    "plt.subplot(121)\n",
    "plt.bar(np.arange(len(comparison)),comparison,width=0.5)\n",
    "plt.title('Median voxel split-half reliability of GLM models')\n",
    "plt.xticks(np.arange(4),np.array(['ASSUMEHRF', 'FITHRF', 'FITHRF\\nGLMDENOISE', 'FITHRF\\nGLMDENOISE\\nRR']));\n",
    "plt.ylim([0.1,0.2])\n",
    "\n",
    "# draw plot showing the change in reliability between the baseline GLM\n",
    "# and the final output of GLMsingle (fithrf-glmdenoise-RR betas)\n",
    "vox_improvement = np.squeeze(vox_reliabilities[3] - vox_reliabilities[0])\n",
    "vox_improvement[nsdgeneral_roi != 1] = np.nan\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(meanvol,cmap='gray',aspect='auto')\n",
    "plt.imshow(vox_improvement,cmap='RdBu_r',clim=(-0.3,0.3),aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.title('change in nsdgeneral voxel reliability**\\ndue to GLMsingle (r)')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.xlabel('\\n**plotting (FITHRF_GLMDENOISE_RR - ASSUMEHRF) reliabilities');\n",
    "\n",
    "# notice that there is systematic increase in reliability moving from the\n",
    "# first to the second to the third to the final fourth version of the GLM\n",
    "# results. these increases reflect, respectively, the addition of HRF\n",
    "# fitting, the derivation and use of data-driven nuisance regressors, and\n",
    "# the use of ridge regression as a way to regularize the instability of\n",
    "# closely spaced experimental trials. depending on one's experimental\n",
    "# goals, it is possible with setting of option flags to activate a subset\n",
    "# of these analysis features.\n",
    "\n",
    "# also, keep in mind that in the above figure, we are simply showing the\n",
    "# median as a metric of the central tendency (you may want to peruse\n",
    "# individual voxels in scatter plots, for example)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
